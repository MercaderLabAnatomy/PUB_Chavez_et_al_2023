{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105ad158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "def assign_gen(well): # function to assign genotype to well\n",
    "    gen=wells_gen_dict.get(well) # get genotype from dictionary\n",
    "    return gen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530af672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate volume of ventricle and atrium\n",
    "def calculate_vol(file_path): \n",
    "    df=pd.read_csv(file_path).set_index(\"Measurement_Name\") # read csv file\n",
    "    well=df.Label.str.split(\":-\",expand=True)[1].str.split(\"--PO\",expand=True)[0][0] # get well from file name\n",
    "    rep=file_path.split(\"No-\")[1].split(\".csv\")[0] # get replicate from file name\n",
    "    if \"Diastole\" in file_path: # if diastole, calculate volume of ventricle and atrium\n",
    "        vol_ventricle = (((1/6)*math.pi)*(df.loc[\"ventricle_short\"][\"Length\"])*(df.loc[\"ventricle_long\"][\"Length\"])**2) # calculate volume of ventricle\n",
    "        vol_atrium  = (((1/6)*math.pi)*(df.loc[\"atrium_short\"][\"Length\"])*(df.loc[\"atrium_long\"][\"Length\"])**2) # calculate volume of atrium\n",
    "        phase=\"Diastole\" # assign phase\n",
    "    elif \"Systole\" in file_path: # if systole, calculate volume of ventricle and atrium\n",
    "        vol_ventricle = (((1/6)*math.pi)*(df.loc[\"ventricle_short\"][\"Length\"])*(df.loc[\"ventricle_long\"][\"Length\"])**2) # calculate volume of ventricle\n",
    "        vol_atrium  = (((1/6)*math.pi)*(df.loc[\"atrium_short\"][\"Length\"])*(df.loc[\"atrium_long\"][\"Length\"])**2) # calculate volume of atrium\n",
    "        phase=\"Systole\" # assign phase\n",
    "    volumes=(well,rep,phase,vol_ventricle,vol_atrium) # create tuple with well, replicate, phase, volume of ventricle and volume of atrium\n",
    "    return volumes # return tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62ced83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input\n",
    "\n",
    "folder_path=\"/AcquiferResults/Ejection_fraction/Measured_diameters/\"\n",
    "df_hb = pd.read_csv(\"C:/AcquiferResults/Heartbeat/result_heartbeat_B.csv\", sep=\";\").rename(columns={\"well\":\"Well\"}) # read csv file with heartbeat data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308df975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ejection fraction tables, make calculation\n",
    "\n",
    "list_directories=os.listdir(folder_path) # get list of directories\n",
    "df_volume_phase=pd.DataFrame([calculate_vol(folder_path+i) for i in list_directories],columns=[\"Well\",\"Repeat\",\"Phase\",\"Volume_Ventricle\",\"Volume_Atrium\"]) # calculate volume of ventricle and atrium\n",
    "df_volume_phase_grouped=df_volume_phase.groupby(by=[\"Well\",\"Phase\"]).mean().reset_index() # group by well and phase\n",
    "df_diastole=df_volume_phase[df_volume_phase[\"Phase\"]==\"Diastole\"] # get diastole\n",
    "df_systole=df_volume_phase[df_volume_phase[\"Phase\"]==\"Systole\"] # get systole\n",
    "df_dis_sys=pd.merge(df_diastole,df_systole, on=[\"Well\",\"Repeat\"]).drop([\"Phase_x\",\"Phase_y\"],axis=1).rename(columns={\"Volume_Ventricle_x\":\"Volume_Ventricle_Diastole\",\"Volume_Atrium_x\":\"Volume_Atrium_Diastole\",\"Volume_Ventricle_y\":\"Volume_Ventricle_Systole\",\"Volume_Atrium_y\":\"Volume_Atrium_Systole\"}) # merge diastole and systole\n",
    "\n",
    "df_dis_sys[\"Ejection_fraction_Ventricle[%]\"]=100*(df_dis_sys[\"Volume_Ventricle_Diastole\"]-df_dis_sys[\"Volume_Ventricle_Systole\"])/df_dis_sys[\"Volume_Ventricle_Diastole\"] # calculate ejection fraction of ventricle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47061244",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate meam for Ejection_fraction_Ventricle[%] > 0 \n",
    "\n",
    "df_dis_sys_mean=df_dis_sys[df_dis_sys[\"Ejection_fraction_Ventricle[%]\"]>0].groupby(\"Well\").mean().reset_index() # calculate mean for ejection fraction of ventricle > 0\n",
    "df_dis_sys_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1287fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign genotype \n",
    "\n",
    "wells = pd.read_csv(\"C:/AcquiferResults/Heartbeat/result_heartbeat_B.csv\", sep=\";\") # read csv file with heartbeat data\n",
    "wells_dropna = wells.dropna()\n",
    "wells_gen = wells_dropna.drop(columns=wells_dropna.columns[0:3]) # drop columns\n",
    "wells_gen_dict=wells_gen.set_index(\"well\").to_dict()[\"gen.\"] # create dictionary with well and genotype\n",
    "df_dis_sys_mean[\"gen.\"]=df_dis_sys_mean[\"Well\"].apply(assign_gen) # assign genotype to well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977403f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged=df_dis_sys_mean.merge(df_hb,on=\"Well\").drop([\"gen._x\",\"Image_title\",\"Rating\"],axis=1) # merge dataframes\n",
    "df_merged[\"Beats_per_min\"]=(df_merged[\"Heartbeat\"]/(300*30))*1000*60 # calculate beats per minute\n",
    "df_merged['Stroke_Volume_Ventricle_nl']=((df_merged.Volume_Ventricle_Diastole)-(df_merged.Volume_Ventricle_Systole))*(10**-9)*1000 # calculate stroke volume of ventricle in nl\n",
    "df_merged['Cardiac_Output_nl_per_min'] = ((df_merged.Beats_per_min)*(df_merged.Stroke_Volume_Ventricle_nl)) # calculate cardiac output in nl/min\n",
    "df_merged # show dataframe\n",
    "df_merged.to_csv(\"nrs_cardiac function.csv\") #  save dataframe as csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe29575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge more results\n",
    "\n",
    "size = pd.read_csv(\"C:/AcquiferResults/Size/20210519_nrs-3dpf_length-genotyping.csv\", delimiter=\";\") # read csv file with size data\n",
    "size_dropna = size.dropna() # drop na\n",
    "size_gen = size_dropna.drop(columns=wells_dropna.columns[0:2]) # drop columns\n",
    "df_full=df_merged.merge(size_gen,on=\"Well\") # merge dataframes\n",
    "df_full # show dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34296fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Length vs Ventricle volume:\", df_full['Length'].corr(df_full['Volume_Ventricle_Diastole'])) # calculate correlation\n",
    "print(\"Lenghh vs Atrium volume:\", df_full['Length'].corr(df_full['Volume_Atrium_Systole'])) # calculate correlation\n",
    "print(\"Length vs Heartbeat:\", df_full['Length'].corr(df_full['Heartbeat'])) # calculate correlation\n",
    "print(\"Length vs Beats_per_min:\", df_full['Length'].corr(df_full['Beats_per_min'])) # calculate correlation\n",
    "print(\"Length vs Stroke_Volume_Ventricle_nl:\", df_full['Length'].corr(df_full['Stroke_Volume_Ventricle_nl']))# calculate correlation\n",
    "print(\"Length vs Cardiac_Output_nl_per_min:\", df_full['Length'].corr(df_full['Cardiac_Output_nl_per_min'])) # calculate correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694525b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df_full.corr(method ='pearson') # calculate pearson correlation\n",
    "corr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e7d7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_volume = corr.drop(columns=corr.columns[4:12]) # drop columns and only keep volume\n",
    "corr_volume = corr_volume[0:4] # keep only first 4 rows\n",
    "corr_volume # show dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0a190f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr_function = corr.drop(columns=corr.columns[0:4]) # drop columns and only keep function\n",
    "corr_function = corr_function[5:10] # keep only rows 5 to 10\n",
    "corr_function # show dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a1ff6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_significant = corr[(corr>0.7) | (corr< -0.7)] # keep only significant correlations\n",
    "corr_significant # show dataframe\n",
    "corr_table=corr_significant # create new dataframe\n",
    "corr_table.to_csv(\"correlation-table.csv\") # save dataframe as csv file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
